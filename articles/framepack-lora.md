---
title: "FramePackã®LoRAå­¦ç¿’ã®ç§çš„ãƒ¡ãƒ¢ï¼†è¨­å®š"
emoji: "ğŸ”–"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["FramePack","HunyuanVideo"]
published: false
---

TODO: ã“ã“ã«kisekaeãªã©ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’å…¥ã‚Œã‚‹

## FramePackã¨ã¯ï¼Ÿ

Hunyuan Videoã®å‹•ç”»ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå‹•ç”»ãƒ»ç”»åƒç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ã–ã£ãã‚Šè¨€ãˆã°æ¬¡ã®ã¨ãŠã‚Šå‹•ç”»ãƒ»ç”»åƒã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ã€‚

```mermaid
flowchart LR
cond[/æ¡ä»¶ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ç”»åƒï¼‰/]
image[/æœ€çµ‚ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç”»åƒ/]
vae_enc[VAEã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼]
in_latent[/å…¥åŠ›ã®æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«/]
out_latent[/å‡ºåŠ›ã®æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«/]
vae_dec[VAEãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼]
video[/å‡ºåŠ›ã®å‹•ç”»/]

image-->vae_enc-->in_latent

%% æœ¬å½“ã¯æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«ãŒæ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã«ã©ã®ã‚ˆã†ã«å¼•ãç¶™ãŒã‚Œã‚‹ã‹ã‚’æ›¸ããŸã‹ã£ãŸ
%% https://github.com/kohya-ss/musubi-tuner/blob/5d63bc1232017e5185a16ea90448de48abfa3fec/src/musubi_tuner/frame_pack/k_diffusion_hunyuan.py#L34

cond-->DiT
in_latent-->DiT-->out_latent
out_latent-->DiT
out_latent-->vae_dec-->video
```

ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã§ã”è¦§ã®é€šã‚Šã€FramePackã¯å‹•ç”»å…¨ä½“ã‚’ã¾ã¨ã‚ã¦ç”Ÿæˆã›ãšã«ã€å‹•ç”»ã‚’åœ§ç¸®ã—ãŸæ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã„ãã¤ã‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†ã‘ã¦ç”Ÿæˆã—ã¾ã™ã€‚

ä¾‹ãˆã°30fpsã§1.2ç§’(72f)ã®å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹å ´åˆã€ã‹ã¤1ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚ãŸã‚Š9æ½œåœ¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å«ã‚€å ´åˆã€ã ã„ãŸã„æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

TODO: ã‚ã¾ã‚Šã«ã‚‚å°ã•ã™ãã‚‹ã®ã§å·®ã—æ›¿ãˆã‚‹...

```mermaid
block-beta
    columns 72
    1Section:36 2Section:36
    1LF:4 2LF:4 3LF:4 4LF:4 5LF:4 6LF:4 7LF:4 8LF:4 9LF:4 10LF:4 11LF:4 12LF:4 13LF:4 14LF:4 15LF:4 16LF:4 17LF:4 18LF:4
    1F 2F 3F 4F 5F 6F 7F 8F 9F 10F 11F 12F 13F 14F 15F 16F 17F 18F 19F 20F 21F 22F 23F 24F 25F 26F 27F 28F 29F 30F 31F 32F 33F 34F 35F 36F 37F 38F 39F 40F 41F 42F 43F 44F 45F 46F 47F 48F 49F 50F 51F 52F 53F 54F 55F 56F 57F 58F 59F 60F 61f 62f 63f 64f 65f 66f 67f 68f 69f 70f 71f 72f
```

<!-- ComfyUIã§FramePackã‚’ä½¿ã£ã¦å‹•ç”»ç”Ÿæˆã‚’ã•ã‚ŒãŸæ–¹ã¯ã€å‡ºåŠ›ã•ã‚Œã‚‹å‹•ç”»ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã¨ã—ã¦æŒ‡å®šã§ãã‚‹å€¤ãŒç‰¹å¾´çš„ã§ã‚ã‚‹ã“ã¨ã«æ°—ä»˜ã„ãŸã¨æ€ã„ã¾ã™ãŒã€ãã‚Œã¯ã“ã‚ŒãŒé–¢ä¿‚ã—ã¦ã„ã¾ã™ã€‚ -->

TODO: ã“ã“ã«é–¢é€£ãƒ„ãƒ¼ãƒ«ã®ã”ãç°¡å˜ãªå¹´è¡¨ã‚’å…¥ã‚Œã‚‹

https://note.com/kohya_ss/n/nbd94d074ddef


## LoRAå­¦ç¿’

### æœ¬å½“ã«LoRAå­¦ç¿’ã®å¿…è¦ãŒã‚ã‚‹ã‹ï¼Ÿ

TODO: åˆã‚ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ¢æ±‚ã—ãŸæ–¹ãŒè‰¯ã„çš„ãªã“ã¨

### ã‚¯ã‚ªãƒªãƒ†ã‚£ãƒ»è²»ç”¨ãƒ»æœŸé–“

ç´”ç²‹ãªå­¦ç¿’ã ã‘è¦‹ã‚Œã°ã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã§æŒ‡å®šã§ãã‚‹å‹•ããƒ»å¤‰åŒ–ã«ã¤ã„ã¦ã¯ã€$25ãƒ»1æ—¥ä»¥å†…ã§å­¦ç¿’ãŒã§ãã¾ã™ã€‚

TODO: å†…è¨³ï¼ˆH100ã§batch_size=16ã§1000stepsã‚ãŸã‚Š1æ™‚é–“ç¨‹åº¦ã€ã¨ã‹ï¼‰

TODO: äººä»¶è²»ã‚„è©¦è¡ŒéŒ¯èª¤ã«ã¤ã„ã¦

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

ç›®çš„ã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºãŒç•°ãªã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€ã‚«ãƒ¡ãƒ©ã‚’ã‚ºãƒ¼ãƒ ã—ãŸã‚Šã€ãƒ‘ãƒ³ã™ã‚‹ã‚ˆã†ãªæŒ™å‹•ã§ã¯ã€ãŠãã‚‰ã20ã‚»ãƒƒãƒˆç¨‹åº¦ã‚ã‚Œã°å­¦ç¿’ã§ãã¾ã™ã€‚

ç›®å®‰ã¨ã—ã¦ã¯ã€1ç¨®é¡ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æŒ‡ç¤ºã§ãã‚‹ç¯„å›²ã®å‹•ãã‚„å¤‰åŒ–ãªã‚‰ã€å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚‚å­¦ç¿’ã§ãã‚‹æ°—ãŒã—ã¾ã™ã€‚

ï¼ˆå€‹äººçš„ã«ã¯ã€LoRA = ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ å­¦ç¿’ã§ã¯ãªãã€Soft Promptãªã©ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã‚‚é”æˆã§ãã‚‹æ°—ãŒã—ã¾ã™ï¼‰

ä¸€æ–¹ã§ã€å…¥åŠ›ã—ãŸå‹•ç”»ãƒ»ç”»åƒã«å¿œã˜ã¦å¤šæ§˜ãªå‹•ãã‚’ã•ã›ã‚‹å ´åˆã€ã‚‚ã†ã¡ã‚‡ã£ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚

ï¼ˆã“ã®ç”»åƒã¯è¨˜äº‹ç”¨ã«æ–°è¦ã«æ›¸ãä¸‹ã‚ã—ã¦ãŠã‚Šã€å®Ÿéš›ã«å­¦ç¿’ã«ä½¿ã£ã¦ã„ã‚‹ã‚‚ã®ã¨ã¯ç•°ãªã‚Šã¾ã™ï¼‰

ã“ã®è¾ºã‚Šã¯æ¢ã£ã¦ã„ã‚‹ã¨ã“ã‚ã§ã™ã€‚

### è¨­å®š

ç§([@xhiorga](https://x.com/xhiroga))ã¯ã€FramePackã®LoRAå­¦ç¿’ã§ã¯ [musubi-tuner](https://github.com/kohya-ss/musubi-tuner) ã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚

2025-07æ™‚ç‚¹ã§ã¯ã€æ¬¡ã®ã‚ˆã†ãªè¨­å®šã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚1ãƒ•ãƒ¬ãƒ¼ãƒ å­¦ç¿’ã®è¨­å®šã§ã™ã€‚

TODO: ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ 

```config.toml
# å‚è€ƒ
# https://github.com/kohya-ss/musubi-tuner/blob/main/docs/framepack_1f.md

dit = "/workspace/models/diffusion_models/FramePackI2V_HY/diffusion_pytorch_model-00001-of-00003.safetensors"
vae = "/workspace/models/vae/diffusion_pytorch_model.safetensors"
text_encoder1 = "/workspace/models/text_encoder/model-00001-of-00004.safetensors"
text_encoder2 = "/workspace/models/text_encoder_2/model.safetensors"
image_encoder = "/workspace/models/image_encoder/model.safetensors"
dataset_config = "/workspace/my-framepack-project/configs/v8/dataset.toml"

blocks_to_swap = 20
split_attn = true
img_in_txt_in_offloading = true

seed = 42
mixed_precision = "bf16"

# Turntableã§ã¯flash_attnã‚’æœ‰åŠ¹åŒ–ã—ã¦ã„ãŸãŒã€One Frameå­¦ç¿’ã§ã®åŠ¹æœãŒåˆ†ã‹ã‚‰ãªã„ã®ã§ä¸€æ—¦sdpaã§ã€‚
sdpa = true
network_module = "networks.lora_framepack"

# ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’å›è»¢ã•ã›ã‚‹ãªã©ã€ã‚·ãƒ³ãƒ—ãƒ«ãªæŒ‡ç¤ºãªã‚‰ network_dim/alpha = 4/4 ç¨‹åº¦ã§ã‚‚å¯èƒ½ã€‚
network_dim = 32
network_alpha = 16

optimizer_type = "adamw8bit"

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® batch_size ãŒ4ãã‚‰ã„ã¾ã§ã¯`1e-3`ã§å®‰å®š
# H100ãªã©ã§å­¦ç¿’ã‚’å›ã™å ´åˆã¯ã€batch_size ã«åˆã‚ã›ã¦`new LR = old * âˆš(sqrt)(new batch size / old batch size)`ã§å¢—ã‚„ã—ã¦ã„ã
learning_rate = 1e-3

gradient_checkpointing = true

max_data_loader_n_workers = 1
persistent_data_loader_workers = true
# ã ã„ãŸã„é€”ä¸­ã§æ­¢ã‚ã‚‹ã®ã§éå¸¸ã«å¤šãè¨­å®šã—ã¦ãŠã
max_train_steps = 10000

timestep_sampling = "shift"
discrete_flow_shift = 6.0

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æšæ•°ã‚„`num_repeat`ã‚’å¤‰æ›´ã™ã‚‹ã¨ã€1epochã”ã¨ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚‚å¤‰ã‚ã‚‹
# ãã‚Œã§ã¯å¤‰æ›´å‰å¾Œã®ãƒ¢ãƒ‡ãƒ«ã‚’ã€åŒã˜ãã‚‰ã„ã®å­¦ç¿’ã®é€²ã¿å…·åˆã§æ¯”è¼ƒã§ããªã„
# ã¾ãŸwandbã«ä¸»ã«è¨˜éŒ²ã•ã‚Œã‚‹ã®ã‚‚ã‚¹ãƒ†ãƒƒãƒ—æ•°ãªã®ã§ã€ã‚¹ãƒ†ãƒƒãƒ—ã§ã®ä¿å­˜ã‚’æ¨å¥¨
save_every_n_steps = 100

# save_state ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ `resume` ã§é€”ä¸­ã‹ã‚‰å­¦ç¿’å†é–‹ã§ãã‚‹
save_state = true
save_state_on_train_end = true

# ã¾ã è©¦ã—ã¦ã„ãªã„ãŒã€HuggingFaceã«ç›´æ¥ä¿å­˜ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚‚ã‚ã‚‹
output_dir = "/workspace/my-framepack-models"
output_name = "my-framepack-project-v8"

# wandbã¯ç„¡æ–™ã§ä½¿ãˆã‚‹ã®ã§çµ¶å¯¾ã«æœ‰åŠ¹åŒ–ã—ãŸæ–¹ãŒè‰¯ã„
# ç‰¹ã« log_config ã‚’æœ‰åŠ¹ã«ã—ã¦ãŠãã¨ã€å­¦ç¿’ã¨è¨­å®šã‚’ç´ã¥ã‘ã‚‰ã‚Œã‚‹ã®ã§åŠ©ã‹ã‚‹
log_with = "wandb"
log_tracker_name = "my-framepack-project"
log_config = true

# é€”ä¸­ã‹ã‚‰å­¦ç¿’å†é–‹ã™ã‚‹å ´åˆã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
# resume = "/workspace/my-framepack-models/my-framepack-project-v8-step00001000-state"

# Sampling options
# å­¦ç¿’ã®é€²åº¦ã‚’è¦‹ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§çµ¶å¯¾ã«æœ‰åŠ¹ã«ã—ãŸæ–¹ãŒè‰¯ã„
sample_at_first = true
sample_every_n_steps = 100
sample_prompts = "/workspace/my-framepack-project/configs/v8/prompts.txt"
fp8_llm = true
vae_chunk_size = 32
vae_spatial_tile_sample_min_size = 128
one_frame = true
```

```dataset.toml
[general]
resolution = [512, 768]
caption_extension = ".txt"
# batch_size = 2 # RTX4090 @ 24GB
# batch_size = 8 # RTX6000Ada @ 48GB
batch_size = 16 # H100 @ 80~96GB
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
# datasetã‚’é€”ä¸­ã‹ã‚‰è¿½åŠ ã—ãŸã‚Šã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç­‰ï¼‰ã‚’é€”ä¸­ã‹ã‚‰è¿½åŠ ã™ã‚‹ã“ã¨ã¯éå¸¸ã«ã‚ˆãã‚ã‚‹
# ãªã®ã§ã©ã¡ã‚‰ã‚‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã¤ã‘ã¦ãŠã„ãŸæ–¹ãŒè‰¯ã„ã€‚
image_jsonl_file = "/workspace/my-framepack-project-dataset/dataset-v1/metadata-v1.jsonl"
cache_directory = "/workspace/framepack-lora/configs/v8/cache/dataset-v1/v1"
num_repeats = 10
fp_1f_clean_indices = [0, 10]
fp_1f_target_index = 5
fp_1f_no_post = true
```

TODO: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®toml

[musubi-tuner](https://github.com/kohya-ss/musubi-tuner)ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ãŒã€ç¾åœ¨ã¯`uv`ã‚„`pip`ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ç‰¹ã«`uv`ã§ç®¡ç†ã™ã‚‹ã®ã‚’å¼·ããŠå‹§ã‚ã—ã¾ã™ã€‚

`uv`ã§ç®¡ç†ã—ãŸå ´åˆã€ä»®æƒ³ç’°å¢ƒã®ç®¡ç†ã‚‚`uv`ãŒè³„ã£ã¦ãã‚Œã¾ã™ã€‚RunPodãªã©ã®GPUã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”¨ã„ã¦ã„ã‚‹å ´åˆã¯ä»®æƒ³ç’°å¢ƒã®æ§‹ç¯‰ãã®ã‚‚ã®ã¯ä¸è¦ã§ã™ãŒã€`uv`ã‚’ã‚¿ã‚¹ã‚¯ãƒ©ãƒ³ãƒŠãƒ¼ã¨ã—ã¦ç”¨ã„ã‚‹ã“ã¨ã§ã€å­¦ç¿’å®Ÿè¡Œæ™‚ã«ç’°å¢ƒæ§‹ç¯‰ãŒã•ã‚Œã¦ã„ãªã‘ã‚Œã°ã€`musubi-tuner`ã‚’å«ã‚€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒè‡ªå‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã€éå¸¸ã«ä¾¿åˆ©ã§ã™ã€‚

ç’°å¢ƒæ§‹ç¯‰ã®æ–¹æ³•ã‚‚éå¸¸ã«ç°¡å˜ã§ã€`uv init --python 3.10`ã®å¾Œã«`uv add "https://github.com/xhiroga/musubi-tuner.git[cu128]"`ã§è‰¯ã„ã¯ãšã§ã™ï¼ˆå‹•ã‹ãªã‹ã£ãŸã‚‰æ•™ãˆã¦ãã ã•ã„ï¼‰

ã¾ãŸã€wandbã®Lossã¯ã ã„ãŸã„æ¬¡ã®ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚ã‚ãã¾ã§å‚è€ƒã§ã™ãŒã€æˆåŠŸã—ã¦ã„ã‚‹æ™‚ã®Lossã¯0.01ä»˜è¿‘ã‹ä»¥å†…ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã‹ã€‚

![alt text](/images/framepack-lora.png)

### GPUã‚¯ãƒ©ã‚¦ãƒ‰

ç­†è€…ã¯RunPodã‚’åˆ©ç”¨ã—ã¦ã„ã¾ã™ã€‚ä»–ã«Vast.ai ã¨ Lambda Cloudã‚’å­¦ç¿’ã«ä½¿ã£ãŸã“ã¨ãŒã‚ã‚Šã¾ã™ãŒã€æ¬¡ã®ç‚¹ã§RunPodã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚

- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ã‚¢ã‚¿ãƒƒãƒ
- Serverlessã‚‚ä½¿ãˆã‚‹ï¼ˆï¼Ÿï¼‰

ãƒã‚·ãƒ³ã«ã¯ã¾ãšRTX6000Adaãªã©ã§ç’°å¢ƒã‚’ä½œã‚Šãã£ã¦2~3stepså›ã—ã€æ¬¡ã«h100ãªã©ã«åˆ‡ã‚Šæ›¿ãˆã¦ï¼ˆé©å®œãƒãƒƒãƒã‚µã‚¤ã‚ºã¨å­¦ç¿’ç‡ã‚‚åˆ‡ã‚Šæ›¿ãˆã‚‹ï¼‰

ã¡ãªã¿ã«RunPodã«ã¯ã€RunPodã®ã‚³ãƒ³ãƒ†ãƒŠã®åœæ­¢ç­‰ã®æ“ä½œãŒå¯èƒ½ãªCLIãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã™ã€‚æ¬¡ã®ã‚ˆã†ã«ã€å­¦ç¿’ãŒçµ‚ã‚ã£ãŸã‚‰ã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

```bash
uv run accelerate launch --num_processes 1 --dynamo_backend=no --mixed_precision bf16 \
-m musubi_tuner.fpack_train_network --image_encoder $$IMAGE_ENCODER --config_file $(CONFIG_FILE) &&\
runpodctl stop pod $RUNPOD_POD_ID
```

accelerateã‚’ä½¿ã†å ´åˆ...

ãªãŠuvx nvitopãŒä¾¿åˆ©

## LoRAã«ã‚ˆã‚‹æ¨è«–

æ³¨æ„ç‚¹ã¯æ¬¡ã®ã¨ãŠã‚Š

- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯å­¦ç¿’æ™‚ã¨å…¨ãåŒã˜ã‚‚ã®ã‚’ä½¿ã†ã€‚(Llamaã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’çµŒç”±ã—ã¦ã„ã‚‹ã«ã‚‚æ‹˜ã‚‰ãš)æ–‡ç« ãŒå°‘ã—é•ã†ã ã‘ã§çµæœãŒåæ˜ ã•ã‚Œãªã„ã“ã¨ãŒã‚ã‚‹ã‚‰ã—ã„ï¼Ÿ


ComfyUIã‚’ç”¨ã„ã¦æ¨è«–ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ä¸€æ–¹musubi-tunerã§ã‚‚ã€ãƒãƒƒãƒæ¨è«–ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚

ComfyUIã®ç’°å¢ƒæ§‹ç¯‰ã¯å¤§å¤‰ã§ã™ã—ã€musubi-tunerã§ã®æ¨è«–ãŒãŠå‹§ã‚ã§ã™ã€‚æ¬¡ã®ã‚ˆã†ã«æŒ‡å®šã§ãã¾ã™ã€‚

```bash
uv run -m musubi_tuner.fpack_generate_video \
--fp8_scaled \
--fp8_llm \
--from_file /workspace/my-framepack-project/configs/v8/prompts.txt \
--output_type latent_images \
--dit /workspace/models/diffusion_models/FramePackI2V_HY/diffusion_pytorch_model-00001-of-00003.safetensors \
--vae /workspace/models/vae/diffusion_pytorch_model.safetensors \
--text_encoder1 /workspace/models/text_encoder/model-00001-of-00004.safetensors \
--text_encoder2 /workspace/models/text_encoder_2/model.safetensors \
--image_encoder /workspace/models/image_encoder/model.safetensors \
--vae_spatial_tile_sample_min_size 128 --vae_chunk_size 32 --blocks_to_swap 20 \
--attn_mode sdpa \
--lora_weight /workspace/my-framepack-models/my-framepack-project-v8-step00005000.safetensors \
--lora_multiplier 1.2 \
--save_path /workspace/my-framepack-models/sample/v8-step00005000-lm1.2
```

## ã¾ã¨ã‚

TODO

TODO: ã“ã“ã«å®£ä¼
