---
title: "musubi-tunerã«ã‚ˆã‚‹FramePackå­¦ç¿’ã®ç§çš„ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹é›†"
emoji: "ğŸ”–"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["FramePack", "HunyuanVideo"]
published: true
---

FramePackã‚’è¿½åŠ å­¦ç¿’ã™ã‚‹ã¨ã€ç”»åƒãƒ»å‹•ç”»ã®ç”Ÿæˆæ™‚ã«ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã¯é›£ã—ã„æŒ‡ç¤ºã‚’å®ˆã‚‰ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãŸã¨ãˆã°ã€ç­‰é€Ÿã§360åº¦å›è»¢ã™ã‚‹ã€ã®ã‚ˆã†ãªæŒ‡ç¤ºãŒå¯èƒ½ã§ã™ã€‚

![FramePackã®LoRAæœ‰ç„¡ã®æ¯”è¼ƒ](/images/framepack-lora-fig1.gif)

FramePackã®LoRAå­¦ç¿’ã«ã‚ãŸã£ã¦ã¯ã€[musubi-tuner](https://github.com/kohya-ss/musubi-tuner)ã‚’ä½¿ã†ã®ãŒç°¡å˜ã§ã™ã€‚ã¨ã¯ã„ãˆæ©Ÿæ¢°å­¦ç¿’ãªã®ã§ã€ã©ã†ã—ã¦ã‚‚è©¦è¡ŒéŒ¯èª¤ãŒã‚ã‚Šã¾ã™ã€‚

ã§ã™ãŒã€è¨­å®šæ¬¡ç¬¬ã§ã€ã€Œå­¦ç¿’é€”ä¸­ã®LoRAã®æ€§èƒ½ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç¢ºèªã™ã‚‹ã€ã€Œå­¦ç¿’ç‡ã®å¤‰åŒ–ã®å½±éŸ¿ã‚’å¯è¦–åŒ–ã™ã‚‹ã€ã€Œå­¦ç¿’å¾Œã«è‡ªå‹•ã§GPUã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è½ã¨ã™ã€ãªã©ã®å·¥å¤«ãŒã§ãã¾ã™ã€‚å…¨ã¦æ›¸ã„ãŸã®ã§ã€å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼

![FramePackã«ã‚ˆã‚‹LoRAå­¦ç¿’ã‚’wandbã§ç®¡ç†ã—ã¦ã„ã‚‹ã‚¹ã‚¯ã‚·ãƒ§](/images/framepack-lora-fig2.gif)

ã¾ãŸã€èª¤ã‚Šã‚„æ”¹å–„ç‚¹ãŒã‚ã‚Œã°ã€è¨˜äº‹ã«å–ã‚Šè¾¼ã¿ãŸã„ã®ã§ãœã²ã‚³ãƒ¡ãƒ³ãƒˆã„ãŸã ã‘ã‚‹ã¨å¹¸ã„ã§ã™ã€‚

## ãã‚‚ãã‚‚FramePackã¨ã¯ï¼Ÿ

[FramePack](https://github.com/lllyasviel/FramePack)ã¯ã€[Hunyuan(æ··å…ƒ = hÃ¹n yuÃ¡n, ãƒ•ãƒ³ãƒ¦ã‚¢ãƒ³) Video](https://github.com/Tencent-Hunyuan/HunyuanVideo)ã®å‹•ç”»ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå‹•ç”»ãƒ»ç”»åƒç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚

Hunyuan Videoã®Diffusion Transformer(DiT)ã«å¯¾ã—ã¦ã€æ—¢ã«ç”Ÿæˆã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã¨æ¡ä»¶ä»˜ã‘ã‚’å…¥åŠ›ã—ã¦æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆã™ã‚‹...ã¨ã„ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã€æŒ‡å®šã•ã‚ŒãŸé•·ã•ã®å‹•ç”»ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

```mermaid
flowchart LR
cond[/æ¡ä»¶ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ç”»åƒï¼‰/]
image[/æœ€çµ‚ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç”»åƒ/]
vae_enc[VAEã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼]
in_latent[/å…¥åŠ›ã®æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«/]
out_latent[/å‡ºåŠ›ã®æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«/]
vae_dec[VAEãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼]
video[/å‡ºåŠ›ã®å‹•ç”»/]

image-->vae_enc-->in_latent

%% æœ¬å½“ã¯æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«ãŒæ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã«ã©ã®ã‚ˆã†ã«å¼•ãç¶™ãŒã‚Œã‚‹ã‹ã‚’æ›¸ããŸã‹ã£ãŸ
%% https://github.com/kohya-ss/musubi-tuner/blob/5d63bc1232017e5185a16ea90448de48abfa3fec/src/musubi_tuner/frame_pack/k_diffusion_hunyuan.py#L34

cond-->DiT
in_latent-->DiT-->out_latent
out_latent-->DiT
out_latent-->vae_dec-->video
```

Stable DiffusionãŒãã†ã§ã‚ã‚‹ã‚ˆã†ã«ã€Hunyuan Videoã®DiTã‚‚ç”»åƒãƒ»å‹•ç”»ã‚’ãƒ”ã‚¯ã‚»ãƒ«ã§ã¯æ‰±ã‚ãšã€VAEã«ã‚ˆã£ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ½œåœ¨ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚ã•ã‚‰ã«FramePackã§ã¯ã€ã„ãã¤ã‹ã®æ½œåœ¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã¾ã¨ã‚ã¦ã€Œã‚»ã‚¯ã‚·ãƒ§ãƒ³ã€ã¨ã—ã¦æ‰±ã£ã¦ã„ã¾ã™ã€‚

ä¾‹ãˆã°30fpsã§1.2ç§’(72f)ã®å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹å ´åˆã€ã‹ã¤1ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚ãŸã‚Š9æ½œåœ¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å«ã‚€å ´åˆã€ãã®é–¢ä¿‚ã¯æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ï¼ˆéå¸¸ã«è¦‹è¾›ãã¦ã™ã¿ã¾ã›ã‚“...ï¼‰

```mermaid
block-beta
    columns 72
    1Section:36 2Section:36
    1LF:4 2LF:4 3LF:4 4LF:4 5LF:4 6LF:4 7LF:4 8LF:4 9LF:4 10LF:4 11LF:4 12LF:4 13LF:4 14LF:4 15LF:4 16LF:4 17LF:4 18LF:4
    1F 2F 3F 4F 5F 6F 7F 8F 9F 10F 11F 12F 13F 14F 15F 16F 17F 18F 19F 20F 21F 22F 23F 24F 25F 26F 27F 28F 29F 30F 31F 32F 33F 34F 35F 36F 37F 38F 39F 40F 41F 42F 43F 44F 45F 46F 47F 48F 49F 50F 51F 52F 53F 54F 55F 56F 57F 58F 59F 60F 61f 62f 63f 64f 65f 66f 67f 68f 69f 70f 71f 72f
```

<!-- ComfyUIã§FramePackã‚’ä½¿ã£ã¦å‹•ç”»ç”Ÿæˆã‚’ã•ã‚ŒãŸæ–¹ã¯ã€å‡ºåŠ›ã•ã‚Œã‚‹å‹•ç”»ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã¨ã—ã¦æŒ‡å®šã§ãã‚‹å€¤ãŒç‰¹å¾´çš„ã§ã‚ã‚‹ã“ã¨ã«æ°—ä»˜ã„ãŸã¨æ€ã„ã¾ã™ãŒã€ãã‚Œã¯ã“ã‚ŒãŒé–¢ä¿‚ã—ã¦ã„ã¾ã™ã€‚ -->

FramePackã«ã‚ˆã‚‹å­¦ç¿’ãƒ»æ¨è«–ã¯ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ã§é€²åŒ–ã‚’é‡ã­ã¦ã„ã¾ã™ã€‚è©³ã—ãã¯[Kohyaã•ã‚“ã®Noteè¨˜äº‹](https://note.com/kohya_ss/n/nbd94d074ddef)ã‚’ã”è¦§ãã ã•ã„ã€‚

## LoRAã®å­¦ç¿’

### æœ¬å½“ã«LoRAãŒå¿…è¦ã‹ï¼Ÿ

FramePackã¯ã€è‡ªç„¶è¨€èªã§ã®å…¥åŠ›ã«å¯¾å¿œã—ã¦ã„ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã€ã‹ãªã‚Šç´°ã‹ã„æŒ‡ç¤ºãŒã§ãã¾ã™ã€‚

ãã®ãŸã‚ã€ã¾ãšã¯ç´ ã®çŠ¶æ…‹ã®æ¨è«–ï¼ˆç”»åƒãƒ»å‹•ç”»ç”Ÿæˆï¼‰ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å·¥å¤«ã—ã€ãã‚Œã§é›£ã—ã‘ã‚Œã°LoRAã‚’è©¦ã™ã®ãŒè‰¯ã„ã§ã—ã‚‡ã†ã€‚æ¢ç´¢ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯LoRAå­¦ç¿’ã§ã‚‚ä½¿ã†ã®ã§ã€ã„ã‚ã°ã‚¹ã‚¿ãƒ¼ãƒˆåœ°ç‚¹ã‚’ã‚´ãƒ¼ãƒ«ã«è¿‘ã¥ã‘ãŸçŠ¶æ…‹ã§å­¦ç¿’ã‚’é€²ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

### ã‚¯ã‚ªãƒªãƒ†ã‚£ãƒ»è²»ç”¨ãƒ»æœŸé–“

ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã§æŒ‡å®šã§ãã‚‹å‹•ããƒ»å¤‰åŒ–ã«ã¤ã„ã¦ã¯ã€ç´”ç²‹ã«å­¦ç¿’ã ã‘ãªã‚‰$25ä»¥å†…ã‹ã¤1æ—¥ä»¥å†…ã§å­¦ç¿’ãŒã§ãã¾ã™ã€‚è¨­å®šã«ã‚ˆã‚Šã¾ã™ãŒã€ä¸€ä¾‹ã¨ã—ã¦ã¯H100ã‚’$2.5/Hourã§8æ™‚é–“å€Ÿã‚Šã¦1,000stepsç¨‹åº¦å­¦ç¿’ã§ãã‚‹æ„Ÿã˜ã§ã—ã‚‡ã†ã‹ã€‚

ã—ã‹ã—ã€å­¦ç¿’é€”ä¸­ã§è¨­å®šã®èª¤ã‚Šã‚„ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚°ã«æ°—ã¥ã„ãŸã‚Šã€ã¯ãŸã¾ãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã—ãŸã‚Šã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ›´ã—ãŸã‚Šã™ã‚‹ã®ãŒæ™®é€šã§ã™ã€‚å€‹äººçš„ã«ã¯ã€åˆã‚ã¦ã®ã‚¿ã‚¤ãƒ—ã®å­¦ç¿’ã§ã¯ã„ã„çµæœãŒå‡ºã‚‹ã¾ã§10~20å›å­¦ç¿’è¨­å®šã‚’å¤‰ãˆã¦ã„ã¾ã™ã€‚ï¼ˆä¾‹ãˆã°[Turntable](https://turntable.sawara.dev)ã«ç”¨ã„ã¦ã„ã‚‹LoRAã¯ãƒãƒ¼ã‚¸ãƒ§ãƒ³18ã§ã™ï¼‰

æœ€çŸ­ã‚’ç‹™ã†ãªã‚‰ã€ã™ã§ã«ä¸Šæ‰‹ãå­¦ç¿’ã§ãã¦ã„ã‚‹äººã‹ã‚‰è¨­å®šã‚’åˆ†ã‘ã¦ã‚‚ã‚‰ã£ãŸã‚Šã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ã‚‚ã‚‰ã†ã®ã‚‚æ‰‹ã§ã™ã€‚[ç§]((https://sawara.dev))ã§ã‚ˆã‘ã‚Œã°ã„ã¤ã§ã‚‚è¦‹ã‚‹ã®ã§ã€ã”é€£çµ¡ãã ã•ã„ï¼

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

ç›®çš„ã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºãŒç•°ãªã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€ã‚«ãƒ¡ãƒ©ã‚’ã‚ºãƒ¼ãƒ ã™ã‚‹ã ã‘ã®ã‚ˆã†ãªã‚·ãƒ³ãƒ—ãƒ«ãªå‹•ãã§ã‚ã‚Œã°ã€å‹•ç”»ãƒ‡ãƒ¼ã‚¿ãŒ20æœ¬ç¨‹åº¦ã‚ã‚Œã°å­¦ç¿’ã§ãã‚‹ã¨æ€ã„ã¾ã™ã€‚

ã€Œ1æ–‡ã§æŒ‡ç¤ºã§ãã‚‹ç¯„å›²ã®å‹•ãã€ãªã‚‰ã€å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚‚å­¦ç¿’ã§ãã‚‹...æ°—ãŒã—ã¾ã™ã€‚

ä¸€æ–¹ã§ã€å…¥åŠ›ã—ãŸå‹•ç”»ãƒ»ç”»åƒã«å¿œã˜ã¦å¤šæ§˜ãªå‹•ãã‚’ã•ã›ã‚‹å ´åˆã€ã‚‚ã†ã¡ã‚‡ã£ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€ã€Œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€ï¼‹ã€ŒæŒ‡å®šã—ãŸç”»é¢¨ã€ã®LoRAã‚’é–‹ç™ºã™ã‚‹å ´åˆã¯ã€éå­¦ç¿’ã‚’é˜²ããŸã‚ã«50~100æšã¯å¿…è¦ãªã®ã§ã¯ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚ã“ã®è¾ºã‚Šã¯æ­£ç›´æ¢ã£ã¦ã„ã‚‹ã¨ã“ã‚ã§ã™ãŒ...ã€‚

### GPUã‚¯ãƒ©ã‚¦ãƒ‰ã®åˆ©ç”¨

FramePackã®LoRAå­¦ç¿’ã‚’å¿«é©ã«è¡Œã†ã«ã¯ã€VRAMãŒä½“æ„Ÿã§30GBä»¥ä¸Šå¿…è¦ã§ã™ã€‚ãã“ã§RTX6000Adaã‚„H100ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã€ç­†è€…ã¯GPUã‚¯ãƒ©ã‚¦ãƒ‰ã®RunPodã‚’åˆ©ç”¨ã—ã¦ã„ã¾ã™ã€‚GPUã‚¯ãƒ©ã‚¦ãƒ‰ã¨ã—ã¦ã¯ Google Colab, Lambda Cloud, RunPod, Vast.aiã‚’å­¦ç¿’ã«ä½¿ã£ãŸã“ã¨ãŒã‚ã‚Šã¾ã™ãŒã€æ¬¡ã®ç‚¹ã§RunPodã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚

- VSCodeã§Remote-SSHæ¥ç¶šã§ãã‚‹ï¼ˆGoogle Colabä»¥å¤–ã§å¯èƒ½ï¼‰
- è¤‡æ•°ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹é–“ã§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ä½¿ã„ã¾ã‚ã›ã‚‹ï¼ˆRunPodã¨Lambda Cloudã§å¯èƒ½ï¼‰
- å€‹äººçš„ã«UIãŒåˆ†ã‹ã‚Šã‚„ã™ã„

è¤‡æ•°ã®è¨­å®šã§ä¸¦åˆ—ã«å­¦ç¿’ã—ãŸã‚Šã€å­¦ç¿’ä¸­ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«åˆ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç«‹ã¦ã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ä½¿ã„ã¾ã‚ã›ãŸæ–¹ãŒè‰¯ã„ã‚“ã§ã™ã­ã€‚

å­¦ç¿’ã®é€²ã‚æ–¹ã¨ã—ã¦ã¯ã€åˆã‚ã«RTX6000Adaãªã©æ¯”è¼ƒçš„å®‰ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§5Stepsãã‚‰ã„å­¦ç¿’ã‚’å›ã—ã¾ã™ã€‚ãã‚Œã§è¨­å®šãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèªã§ããŸã‚‰ã€H100ãªã©ã«åˆ‡ã‚Šæ›¿ãˆã¦æœ¬æ ¼çš„ã«å›ã™ã“ã¨ãŒå¤šã„ã§ã™ã€‚
ï¼ˆã‚‚ã£ã¨ã‚‚ã€ãã“ã¾ã§GPUã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒä½™ã£ã¦ãªã„ã“ã¨ã‚‚å¤šã„ã®ã§ã€åˆã‚ã«ç¢ºä¿ã—ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ãã®ã¾ã¾ä½¿ã†ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ï¼‰

ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¯æœ€ä½200GBç¨‹åº¦å¿…è¦ã§ã™ã€‚ã“ã‚Œã‚‚è¨­å®šã§å¤§ããç•°ãªã‚Šã¾ã™ãŒã€FramePackã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãªã©ã‚‚å«ã‚€ï¼‰ã§100GBã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§20GBã€å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã§40GBã¨ã„ã†æ„Ÿã˜ã§ã—ã‚‡ã†ã‹ã€‚

### è¨­å®š

ç§([@xhiorga](https://x.com/xhiroga))ã¯ã€FramePackã®LoRAå­¦ç¿’ã§ã¯ [musubi-tuner](https://github.com/kohya-ss/musubi-tuner) ã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚

2025-07æ™‚ç‚¹ã§ã¯ã€æ¬¡ã®ã‚ˆã†ãªè¨­å®šã§1ãƒ•ãƒ¬ãƒ¼ãƒ å­¦ç¿’ã‚’è¡Œãªã£ã¦ã„ã¾ã™ã€‚

#### ãƒªãƒã‚¸ãƒˆãƒªæ¦‚è¦

æ¬¡ã®ã‚ˆã†ãªæ§‹æˆã§ã™ã€‚å­¦ç¿’è¨­å®šã¯`configs`ä»¥ä¸‹ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã—ã¦ç®¡ç†ã—ã¦ã„ã¾ã™ã€‚

```
- .git
- configs
  - v1
    - config.toml
    - dataset.toml
    - prompts.txt
  - v2
  - ...
- .gitignore
- .python-version
- pyproject.toml
- Makefile
- README.md
- uv.lock
```

#### pyproject.toml

ç¶šã„ã¦ã€å­¦ç¿’ã®ãŸã‚ã®ç’°å¢ƒã§ã™ã€‚

```
[project]
name = "my-framepack-project"
version = "0.1.0"
requires-python = ">=3.10"
dependencies = [
    "sageattention>=1.0.6",
    "musubi-tuner[cu128]",
    "wandb>=0.21.0",
    "toml>=0.10.2",
]

[tool.uv]
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥å…ˆã‚’`.venv`ã¨åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã«ã—ãªã„ã¨ã€GPUã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆã”ã¨ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒèµ°ã‚‹ã®ã§æ³¨æ„
cache-dir = "/workspace/.uv_cache"

[tool.uv.sources]
musubi-tuner = { git = "https://github.com/kohya-ss/musubi-tuner.git" }

```

[musubi-tuner](https://github.com/kohya-ss/musubi-tuner)ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«ã¯`uv`ã‚’ç”¨ã„ã‚‹ã®ã‚’å¼·ããŠå‹§ã‚ã—ã¾ã™ã€‚

`uv`ã§ç®¡ç†ã—ãŸå ´åˆã€ä»®æƒ³ç’°å¢ƒã®ç®¡ç†ã‚‚`uv`ãŒè³„ã£ã¦ãã‚Œã¾ã™ã€‚RunPodãªã©ã®GPUã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”¨ã„ã¦ã„ã‚‹å ´åˆã¯ä»®æƒ³ç’°å¢ƒã®æ§‹ç¯‰ãã®ã‚‚ã®ã¯ä¸è¦ã§ã™ãŒã€`uv`ã‚’ã‚¿ã‚¹ã‚¯ãƒ©ãƒ³ãƒŠãƒ¼ã¨ã—ã¦ç”¨ã„ã‚‹ã“ã¨ã§ã€å­¦ç¿’å®Ÿè¡Œæ™‚ã«ç’°å¢ƒæ§‹ç¯‰ãŒã•ã‚Œã¦ã„ãªã‘ã‚Œã°ã€`musubi-tuner`ã‚’å«ã‚€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒè‡ªå‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã€éå¸¸ã«ä¾¿åˆ©ã§ã™ã€‚

#### config.toml

æ¬¡ã®ã‚ˆã†ãªæ§‹æˆã§ã™ã€‚ãªãŠã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã”ã¨ã®å·®åˆ†ã‚’æ¯”è¼ƒã—ã‚„ã™ã„ã‚ˆã†ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯ãªã`toml`ã§ç®¡ç†ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

```/workspace/my-framepack-project/configs/v1/config.toml
dit = "/workspace/models/diffusion_models/FramePackI2V_HY/diffusion_pytorch_model-00001-of-00003.safetensors"
vae = "/workspace/models/vae/diffusion_pytorch_model.safetensors"
text_encoder1 = "/workspace/models/text_encoder/model-00001-of-00004.safetensors"
text_encoder2 = "/workspace/models/text_encoder_2/model.safetensors"
image_encoder = "/workspace/models/image_encoder/model.safetensors"
dataset_config = "/workspace/my-framepack-project/configs/v8/dataset.toml"

blocks_to_swap = 20
split_attn = true
img_in_txt_in_offloading = true

seed = 42
mixed_precision = "bf16"

sdpa = true
network_module = "networks.lora_framepack"

# ã‚·ãƒ³ãƒ—ãƒ«ãªLoRAãªã‚‰4/4ç¨‹åº¦ã§OKã€‚
network_dim = 32
network_alpha = 16

optimizer_type = "adamw8bit"

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® batch_size æ¬¡ç¬¬ã€‚
# batch_size = 4 ãã‚‰ã„ã¾ã§ã¯`1e-3`ã§å®‰å®š
# ãã‚Œä»¥é™ã€batch_size ã«åˆã‚ã›ã¦`new LR = old * âˆš(sqrt)(new batch size / old batch size)`ã§å¢—ã‚„ã™ã€‚
learning_rate = 1e-3

gradient_checkpointing = true

max_data_loader_n_workers = 1
persistent_data_loader_workers = true

# ã ã„ãŸã„é€”ä¸­ã§æ­¢ã‚ã‚‹ã®ã§éå¸¸ã«å¤šãè¨­å®šã—ã¦ãŠã
max_train_steps = 5000

timestep_sampling = "shift"
discrete_flow_shift = 6.0

fp8_llm = true
vae_chunk_size = 32
vae_spatial_tile_sample_min_size = 128
one_frame = true

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æšæ•°ã‚„`num_repeat`ã‚’å¤‰æ›´ã™ã‚‹ã¨ã€1epochã”ã¨ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚‚å¤‰ã‚ã‚‹
# ãã‚Œã§ã¯å¤‰æ›´å‰å¾Œã®ãƒ¢ãƒ‡ãƒ«ã‚’ã€åŒã˜ãã‚‰ã„ã®å­¦ç¿’ã®é€²ã¿å…·åˆã§æ¯”è¼ƒã§ããªã„
# ã¾ãŸwandbã«ä¸»ã«è¨˜éŒ²ã•ã‚Œã‚‹ã®ã‚‚ã‚¹ãƒ†ãƒƒãƒ—æ•°ãªã®ã§ã€ã‚¹ãƒ†ãƒƒãƒ—ã§ã®ä¿å­˜ã‚’æ¨å¥¨
# ãŸã ã—ãƒã‚·ãƒ³ã‚’nå°ä½¿ã†ã¨ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Šã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¯nåˆ†ã®1ã«ãªã‚‹ãŒ...
save_every_n_steps = 100

# æŒ‡å®šã—ãŸã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã€å­¦ç¿’é€”ä¸­ã®LoRAã‚’ä½¿ã£ã¦ç”»åƒ/å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹
sample_at_first = true
sample_every_n_steps = 100
sample_prompts = "/workspace/my-framepack-project/configs/v1/prompts.txt"

# save_state ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ `resume` ã§é€”ä¸­ã‹ã‚‰å­¦ç¿’å†é–‹ã§ãã‚‹
save_state = true
save_state_on_train_end = true

# é€”ä¸­ã‹ã‚‰å­¦ç¿’å†é–‹ã™ã‚‹å ´åˆã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
# resume = "/workspace/my-framepack-models/my-framepack-project-v1-step00001000-state"

# ãƒ¢ãƒ‡ãƒ«ã¯HuggingFaceã«ç›´æ¥ä¿å­˜ã™ã‚‹ãŒã€ãã®å ´åˆã‚‚ output_dir ã®è¨­å®šã¯å¿…è¦
output_dir = "/workspace/my-framepack-models"
output_name = "my-framepack-project-v8"

huggingface_repo_id = "my-id/my-framepack-models"
huggingface_repo_type = "model"
huggingface_path_in_repo = "/"
save_state_to_huggingface = true

# wandbã¯ç„¡æ–™ã§ä½¿ãˆã‚‹ã®ã§æœ‰åŠ¹åŒ–ã™ã¹ã
# ç‰¹ã« log_config ã‚’æœ‰åŠ¹ã«ã—ã¦ãŠãã¨ã€ã©ã®Lossé·ç§»ãŒã©ã®è¨­å®šã ã£ãŸã‹ç¢ºèªã§ãã¦åŠ©ã‹ã‚‹
# ã‚µãƒ³ãƒ—ãƒ«ã—ãŸç”»åƒãƒ»å‹•ç”»ã‚‚wandbã«ä¿å­˜ã§ãã‚‹
log_with = "wandb"
log_tracker_name = "my-framepack-project"
log_config = true
```

#### dataset.toml

æ¬¡ã®ã‚ˆã†ãªè¨­å®šã§ã™ã€‚ãªãŠã€kisekaeichiã§ã®å­¦ç¿’ã‚’å‰æã¨ã—ã¦ã„ã¾ã™ã€‚

```/workspace/my-framepack-project/configs/v1/dataset.toml
[general]
resolution = [512, 768]
caption_extension = ".txt"
# batch_size = 2 # RTX4090 @ 24GB
# batch_size = 8 # RTX6000Ada @ 48GB
batch_size = 16 # H100 @ 80~96GB
enable_bucket = true
bucket_no_upscale = false

[[datasets]]
# datasetã‚’é€”ä¸­ã‹ã‚‰è¿½åŠ ã—ãŸã‚Šã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç­‰ï¼‰ã‚’é€”ä¸­ã‹ã‚‰è¿½åŠ ã™ã‚‹ã“ã¨ã¯éå¸¸ã«ã‚ˆãã‚ã‚‹
# ãªã®ã§ã©ã¡ã‚‰ã‚‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã¤ã‘ã¦ãŠã„ãŸæ–¹ãŒè‰¯ã„ã€‚
image_jsonl_file = "/workspace/my-framepack-project-dataset/dataset-v1/metadata-v1.jsonl"
cache_directory = "/workspace/framepack-lora/configs/v1/cache/dataset-v1/v1"
num_repeats = 10
fp_1f_clean_indices = [0, 10]
fp_1f_target_index = 5
fp_1f_no_post = true
```

#### metadata.jsonl

æ¬¡ã®ã‚ˆã†ãªè¨­å®šã§ã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯[ã¨ã‚Šã«ãã•ã‚“ã®Note](https://note.com/tori29umai/n/n0704b7a05ecf)ãŒå…ƒãƒã‚¿ã§ã™ã€‚

```/workspace/my-framepack-project-dataset/dataset-v1/metadata-v1.jsonl
{"image_path": "/workspace/my-framepack-project-dataset/dataset-v1/girl-pose.png", "control_path_0": "/workspace/my-framepack-project-dataset/dataset-v1/girl-pose.png", "control_path_1": "/workspace/my-framepack-project-dataset/dataset-v1/girl.png", "caption": "Convert reference images of poses and expressions into character design images."}
...
```

#### prompts.txt

ã‚µãƒ³ãƒ—ãƒ«ç”¨ã®ç”»åƒãƒ»å‹•ç”»ã¯ã€æ¬¡ã®ã‚ˆã†ãªå½¢å¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»è¨­å®šã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§å‡ºåŠ›ã§ãã¾ã™ã€‚wandbã‚’ä½¿ãˆã°ã€æ¬¡ã®ã‚ˆã†ã«å‡ºåŠ›ã—ãŸç”»åƒã‚’å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—åˆ¥ã«ç¢ºèªã§ãã¾ã™ã€‚

![wandbã§ã‚¹ãƒ†ãƒƒãƒ—åˆ¥ã®æ¨è«–çµæœã‚’ç¢ºèªã™ã‚‹ã‚¹ã‚¯ã‚·ãƒ§](/images/framepack-lora-fig4.gif)

ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾‹ã§ã™ã€‚ã¾ãšã¯å‹•ç”»ã®å ´åˆã€‚

```/workspace/my-framepack-project/configs/v1/prompts.txt
rotating 360 degrees. --w 512 --h 960 --f 81 --d 42 --s 20 --i /workspace/data/asagi-chan/chatgpt-4o/asagi-chan-stand-up.png
...
```

ç”»åƒã®1få­¦ç¿’ã®ä¾‹ã§ã™ã€‚`--of`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯kisekaeichiã®æƒ³å®šã§ã™ã€‚

```/workspace/my-framepack-project/configs/v1/prompts.txt
# ã‚³ãƒ¡ãƒ³ãƒˆã‚‚å¯èƒ½
Convert reference images of poses and expressions into character design images. --w 512 --h 768 --d 42 --s 20 --i /workspace/my-framepack-project-dataset/validation/boy-pose.png --ci /workspace/my-framepack-project-dataset/validation/boy-pose.png --ci /workspace/my-framepack-project-dataset/validation/boy.png --of target_index=9,control_index=0;1,no_2x,no_4x,no_post
...
```

æ³¨æ„ç‚¹ã¨ã—ã¦ã€ã‚µãƒ³ãƒ—ãƒ«ã®å…¥åŠ›ã«ã¯å­¦ç¿’ã«å«ã‚ã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã‚‚ç”¨ã„ã¾ã—ã‚‡ã†ã€‚ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’æ¸¬ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã§ã™ã€‚

#### å­¦ç¿’ç”¨ã‚³ãƒãƒ³ãƒ‰

ç§ã¯`Makefile`ã«ã¾ã¨ã‚ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚

```Makefile
train:
	IMAGE_ENCODER=$$(uv run python -c 'import toml; d=toml.load(open("$(CONFIG_FILE)", "r")); print(d["image_encoder"])')

	uv run wandb login $(WANDB_API_KEY)
	uv  run \
		accelerate launch \
			--num_processes 1 \
			--dynamo_backend=no \
			--mixed_precision bf16 \
			-m musubi_tuner.fpack_train_network \
				--image_encoder $$IMAGE_ENCODER \
				--config_file $(CONFIG_FILE) \
				--huggingface_token $(HUGGINGFACE_TOKEN)
	sleep 10m ; runpodctl stop pod $(RUNPOD_POD_ID) &

cache:
	DATASET_CONFIG=$$(uv run python -c 'import toml; d=toml.load(open("$(CONFIG_FILE)", "r")); print(d["dataset_config"])')
	VAE=$$(uv run python -c 'import toml; d=toml.load(open("$(CONFIG_FILE)", "r")); print(d["vae"])')
	IMAGE_ENCODER=$$(uv run python -c 'import toml; d=toml.load(open("$(CONFIG_FILE)", "r")); print(d["image_encoder"])')
	TEXT_ENCODER1=$$(uv run python -c 'import toml; d=toml.load(open("$(CONFIG_FILE)", "r")); print(d["text_encoder1"])')
	TEXT_ENCODER2=$$(uv run python -c 'import toml; d=toml.load(open("$(CONFIG_FILE)", "r")); print(d["text_encoder2"])')

	uv run -m musubi_tuner.fpack_cache_latents \
		--dataset_config $$DATASET_CONFIG \
		--vae $$VAE \
		--image_encoder $$IMAGE_ENCODER \
		--one_frame

	uv run -m musubi_tuner.fpack_cache_text_encoder_outputs \
		--dataset_config $$DATASET_CONFIG \
		--text_encoder1 $$TEXT_ENCODER1 \
		--text_encoder2 $$TEXT_ENCODER2 \
		--batch_size 16
```

ãƒã‚¤ãƒ³ãƒˆã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ã€‚

- ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’é‡ã­ãŸæ™‚ã«è¨­å®šã®å¤‰æ›´æ¼ã‚ŒãŒãªã„ã‚ˆã†ã€`config.toml`ã‚’ä¿¡é ¼ã§ãã‚‹å”¯ä¸€ã®æƒ…å ±æºã¨ã—ã¦ã€ãã‚Œä»¥å¤–ã®å€¤ã¯`config.toml`ã‚’å‹•çš„ã«ãƒ‘ãƒ¼ã‚¹ã—ã¦å–å¾—ã—ã¦ã„ã¾ã™ã€‚
- RunPodã§ã®å®Ÿè¡Œã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚å­¦ç¿’å¾Œã«`sleep 10m ; runpodctl stop pod $(RUNPOD_POD_ID) &`ã¨å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€è‡ªå‹•ã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è½ã¨ã›ã¾ã™ã€‚

### å®Ÿè¡Œ

`tmux`ãªã©ã§ä»®æƒ³ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’ä½œæˆã—ã¦ã€ãã®ä¸­ã§å­¦ç¿’ã‚’èµ°ã‚‰ã›ã¾ã™ã€‚åŒæ™‚ã«ã€åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§`uvx nvitop`ã‚’å®Ÿè¡Œã—ã¦GPUã®åˆ©ç”¨çŠ¶æ³ã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ç‰¹ã«ã€å­¦ç¿’ã®åˆæœŸã§ã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã€GPUãŒã©ã®ç¨‹åº¦ä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ã¯ç´°ã‹ãç¢ºèªã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚

![alt text](/images/framepack-lora-fig3.png)

çŠ¶æ³ã«ã‚ˆã£ã¦å…¨ãç•°ãªã‚‹ã¨æ€ã„ã¾ã™ãŒã€ä¸€ä¾‹ã¨ã—ã¦å­¦ç¿’æ™‚ã®wandbã®Lossã¯æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚æˆåŠŸã—ã¦ã„ã‚‹æ™‚ã®Lossã¯0.01ä»˜è¿‘ã‹ä»¥å†…ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã‹ã€‚

![alt text](/images/framepack-lora.png)

Lossã®é·ç§»ãŒæ™®æ®µã¨é•ã†ãªï¼Ÿã¨æ€ã£ãŸã‚‰ã€è¨­å®šã‚’è¦‹ç›´ã—ã¦ã‚‚ã„ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ç§ã®å ´åˆã€`resume`ãªã—ã§å­¦ç¿’ã—ã¦ã„ããªã‚ŠLossãŒ`0.01`ä»˜è¿‘ã ã£ãŸã‚‰ã€å…¥åŠ›ç”»åƒã¨æ•™å¸«ç”»åƒãŒåŒã˜ç”»åƒã«ãªã£ã¡ã‚ƒã£ã¦ãŸã€ã¨ã„ã†ã“ã¨ãŒã‚ã‚Šã¾ã—ãŸã€‚

## LoRAã‚’ç”¨ã„ãŸæ¨è«–

å­¦ç¿’ã—ãŸLoRAã®æ€§èƒ½ã‚’æ¸¬ã‚‹ã«ã¯ã€ComfyUIã‚’ç”¨ã„ã¦æ¨è«–ã™ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚

[FramePackã®ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ¼ãƒ‰](https://github.com/xhiroga/ComfyUI-FramePackWrapper_PlusOne)ã‚‚ã‚ã‚Šã¾ã™ãŒã€å®Ÿã¯musubi-tunerã§ã‚‚ãƒãƒƒãƒæ¨è«–ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬¡ã®ã‚ˆã†ã«æŒ‡å®šã™ã‚Œã°OKã§ã™ã€‚

```bash
uv run -m musubi_tuner.fpack_generate_video \
--fp8_scaled \
--fp8_llm \
--from_file /workspace/my-framepack-project/configs/v8/prompts.txt \
--output_type latent_images \
--dit /workspace/models/diffusion_models/FramePackI2V_HY/diffusion_pytorch_model-00001-of-00003.safetensors \
--vae /workspace/models/vae/diffusion_pytorch_model.safetensors \
--text_encoder1 /workspace/models/text_encoder/model-00001-of-00004.safetensors \
--text_encoder2 /workspace/models/text_encoder_2/model.safetensors \
--image_encoder /workspace/models/image_encoder/model.safetensors \
--vae_spatial_tile_sample_min_size 128 --vae_chunk_size 32 --blocks_to_swap 20 \
--attn_mode sdpa \
--lora_weight /workspace/my-framepack-models/my-framepack-project-v8-step00005000.safetensors \
--lora_multiplier 1.2 \
--save_path /workspace/my-framepack-models/sample/v8-step00005000-lm1.2
```

## ã¾ã¨ã‚

FramePackã®LoRAå­¦ç¿’ã«ã¤ã„ã¦ã€ã€Œæœ‰è­˜è€…ã«æ•™ãˆã¦ã‚‚ã‚‰ã†ã®ãŒä¸€ç•ªæ—©ã„ãŒã€æ…£ã‚Œã‚Œã°$25ã®å­¦ç¿’ã‚’5~20å›ç¨‹åº¦å›ã™ã“ã¨ã§ç›®çš„ã®ãƒ¢ãƒ‡ãƒ«ãŒé–‹ç™ºã§ãã‚‹ã€ã€Œuvã¨tomlãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨ã„ãŸæ§‹æˆç®¡ç†ã€ã€Œwandbã‚’ç”¨ã„ãŸå­¦ç¿’ã®å¯è¦–åŒ–ã€ã®ã‚³ãƒ„ã‚’æ›¸ãã¾ã—ãŸã€‚

çš†æ§˜ã®æ¢ç©¶ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚ã“ã“ã§ã¯å…¬é–‹ã—ã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã‚‚ã‚ã‚‹ã®ã§ã€å­¦ç¿’ã§æ°—ã«ãªã‚‹ã“ã¨ãŒã‚ã‚Œã°ãŠæ°—è»½ã«[ã•ã‚ã‚‰](https://sawara.dev)ã¾ã§ã”é€£çµ¡ãã ã•ã„ï¼ãŠä»•äº‹ã§ã®ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã‚‚ãŠå—ã‘ã—ã¦ã„ã¾ã™ğŸ™
