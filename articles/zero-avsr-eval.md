---
title: 'å¤šè¨€èªå¯¾å¿œã®èª­å”‡ãƒ¢ãƒ‡ãƒ« "Zero-AVSR" ã‚’å‹•ã‹ã™'
emoji: "ğŸ’„"
type: "tech"
topics: ["zero-avsr", "marc", "av-hubert", "hubert"]
published: false
---

## TL;DR


## å‹•æ©Ÿ



## AVSRã¨ã¯ï¼Ÿ

èª­å”‡ã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹ç ”ç©¶ã‚’ASR, éŸ³å£°ã¨èª­å”‡ã®ä¸¡æ–¹ã®æƒ…å ±ã‚’ä½¿ã£ã¦ç™ºè©±å†…å®¹ã‚’èªè­˜ã™ã‚‹ç ”ç©¶ã‚’ AVSR (Audio-Visual Speech Recognition) ã¨ã„ã„ã¾ã™ã€‚




## Zero-AVSRã«ã¤ã„ã¦

Zero-AVSRã¯ã€2025å¹´3æœˆã«arXivã«ã¦åˆç‰ˆãŒå…¬é–‹ã•ã‚ŒãŸã€å¤šè¨€èªå¯¾å¿œã®AVSRãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚

æ§‹æˆã‚’å¤§ããåˆ†ã‘ã‚‹ã¨ã€éŸ³å£°ãƒ»èª­å”‡æƒ…å ±ã‚’ãƒ­ãƒ¼ãƒå­—ã«å¤‰æ›ã™ã‚‹ "AV-Romanizer" ã¨ã€ãƒ­ãƒ¼ãƒå­—ã‚’æ–‡ç« ã«å¤‰æ›ã™ã‚‹LLMã®2æ®µã‹ã‚‰æˆã‚Šç«‹ã£ã¦ã„ã¾ã™ã€‚ç‰¹ã« "AV-Romanizer" ã¯ã€éŸ³å£°ã¨èª­å”‡ã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã®ç‰¹å¾´æŠ½å‡ºå™¨ã®1ã¤ã§ã‚ã‚‹ "AV-HuBERT" ã®ãƒ˜ãƒƒãƒ‰ã‚’ãƒ­ãƒ¼ãƒå­—åˆ†é¡ã‚¿ã‚¹ã‚¯ç”¨ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã¨ãªã£ã¦ãŠã‚Šã€å…¨ä½“åƒã‚’èª­ã¿è§£ãã®ãŒå°‘ã€…å¤§å¤‰ã§ã—ãŸã€‚è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚

### å…ˆè¡Œç ”ç©¶: HuBERT ãŠã‚ˆã³ AV-HuBERT

éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’é€£ç¶šã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦è¡¨ç¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã†ã¡ã€MetaãŒè‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’ç”¨ã„ã¦é–‹ç™ºã—ãŸã®ãŒHuBERTã§ã™ã€‚AV-HuBERTã¯HuBERTã‚’éŸ³å£°ãƒ»è¦–è¦šã«æ‹¡å¼µã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚

ã”ãç°¡å˜ã«è¨€ãˆã°ã€HuBERTã¯éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’20msã”ã¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã«åˆ†å‰²ã—ã€ãã‚Œãã‚Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’256~1024æ¬¡å…ƒï¼ˆãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«ã‚ˆã£ã¦ç•°ãªã‚Šã¾ã™ï¼‰ã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã—ãŸä¸Šã§ã€ã•ã‚‰ã«ä¸‹æµã‚¿ã‚¹ã‚¯ã”ã¨ã«ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ã‚’è£…ç€ã—ã¦æ¨è«–ã‚’è¡Œã„ã€æ€§èƒ½ã‚’æ¸¬ã£ã¦ã„ã¾ã™ã€‚

ä¾‹ãˆã°ã€HuBERTã§ASRã‚’è¡Œã†å ´åˆã®æ§‹æˆã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ã€‚

```mermaid
```


### Cascaded Zero-AVSR



```mermaid
flowchart LR

```

### (Directly Integrated) Zero-AVSR

é–“ã«ãƒ­ãƒ¼ãƒå­—ã‚’æŒŸã‚€ `Cascated Zero-AVSR` ã¨ã¯ç•°ãªã‚‹ã€éŸ³å£°ãƒ»èª­å”‡ã‹ã‚‰æŠ½å‡ºã—ãŸç‰¹å¾´ã‚’ãã®ã¾ã¾LLMã«çµ±åˆã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒææ¡ˆã•ã‚Œã¦ã„ã¾ã™ã€‚è«–æ–‡ã§ã¯ã“ã¡ã‚‰ã‚’å˜ã« `Zero-AVSR` ã¨ã‚ˆã‚“ã§ã„ã¾ã™ã€‚æœ¬è¨˜äº‹ã§ã¯ã€ç‰¹ã« `Cascaded Zero-AVSR` ã¨åŒºåˆ¥ã—ãŸã„å ´åˆã« `Directly Integrated Zero AVSR` ã¨å‘¼ã¶ã“ã¨ã«ã—ã¾ã™ã€‚æ¬¡ã®ã‚ˆã†ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚


```mermaid
flowchart LR

```




```mermaid
flowchart TB
  subgraph AVRomanizer["AV-Romanizer Pretraining (AV-HuBERT)"]
    audio["Audio waveform"] -->|log-mel fbank| audEnc["Audio encoder (linear layer)"]
    video["Mouth ROI video"] --> visEnc["Visual encoder (3D ResNet-18)"]
    audEnc --> fuse["Concat + linear W"]
    visEnc --> fuse
    fuse --> transformer["Transformer encoder (24 layers, d=1024, heads=16)"]
    transformer --> romanHead["Linear projection to romanized tokens"]
    romanHead --> romanOut["Romanized token sequence"]
    romanOut --> ctc["CTC loss"]
  end

  transformer --> fav["Fused AV feature f_av"]

  subgraph Task1["Task 1: Align AV features with LLM"]
    fav --> lenComp["Length compressor (1D conv stride 2)"]
    lenComp --> adapter["Adapter to LLM embedding space"]
    instruction["Instruction prompt tokens"] --> instrEmb["Instruction embeddings"]
    adapter --> concat1["Concatenate embeddings"]
    instrEmb --> concat1
    concat1 --> llm1["LLM (Llama3.2-3B, frozen base) with QLoRA"]
    llm1 --> output1["Language-specific transcript"]
    output1 --> loss1["Language modeling loss"]
  end

  subgraph Task2["Task 2: Text-only de-romanization"]
    romanCorpus["Romanized transcripts (MARC text only)"] --> concat2["Tokenized prompt"]
    concat2 --> llm2["LLM (shared QLoRA adapters)"]
    llm2 --> output2["Language-specific transcript"]
    output2 --> loss2["Language modeling loss"]
  end

  llm1 --- shared["Shared QLoRA weights"]
  shared --- llm2
```

## Zero-AVSRã‚’è©•ä¾¡ã™ã‚‹

### MARC ã‚’ç”¨æ„ã™ã‚‹

### Cascaded Zero-AVSR ã‚’è©•ä¾¡ã™ã‚‹

ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ã€`Cascaded Zero-AVSR`ã®æ€§èƒ½ã‚’è©•ä¾¡ã—ã¾ã™ã€‚

MARCã®ãƒ‰ã‚¤ãƒ„èªã‚³ãƒ¼ãƒ‘ã‚¹ã‚’å¯¾è±¡ã«AVSRã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€`Cascaded Zero-AVSR` å…¨ä½“ã§ãã‚Œãã‚ŒWER: 29%, CER: 17%ç¨‹åº¦ã®æ€§èƒ½ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚ã¾ãŸã€`AV-Romanizer` ãŒå‡ºåŠ›ã™ã‚‹ãƒ­ãƒ¼ãƒå­—ï¼†å˜èªåŒºåˆ‡ã‚Šæ–‡å­—ã‚’å˜èªåˆ—ã¨è¦‹åšã—ãŸå ´åˆã€WER: 42%ç¨‹åº¦ã®æ€§èƒ½ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚

å®Ÿè¡Œæ‰‹é †ã«ã¤ã„ã¦ã¯ã€ç§ãŒãƒ•ã‚©ãƒ¼ã‚¯ã—ãŸ[`Zero-AVSR`](https://github.com/xhiroga/zero-avsr/)ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ã”è¦§ãã ã•ã„ã€‚

https://github.com/xhiroga/zero-avsr

å®Ÿè¡Œã®æ§˜å­ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ã€‚

```log
% bash scripts/stage1/eval.sh
[2025-10-08 14:56:01,014][__main__][INFO] - /home/hiroga/Documents/GitHub/zero-avsr/pretrained_models/av-romanizer/all/checkpoint_best.pt

.........

[2025-10-08 15:03:54,743][__main__][INFO] - ---------------------
[2025-10-08 15:03:54,744][__main__][INFO] - HYPO: gibts su
[2025-10-08 15:03:54,745][__main__][INFO] - REF: gebt es zu
[2025-10-08 15:03:54,745][__main__][INFO] - ---------------------
[2025-10-08 15:03:54,746][__main__][INFO] - HYPO: warum dat
[2025-10-08 15:03:54,746][__main__][INFO] - REF: warum das denn
[2025-10-08 15:03:54,746][__main__][INFO] - ---------------------
[2025-10-08 15:03:54,746][__main__][INFO] - Processed 735 sentences (0 tokens) in 0.0s 735000000.00 sentences per second, 1000000.00 tokens per second)
[2025-10-08 15:03:54,748][__main__][INFO] - Word error rate: 41.5876
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 735/735 [00:00<00:00, 11753.95it/s]
Zero shot language WER, CER: 29.161822217524573, 17.073924509642328
```

ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€`zero-avsr/evaluation/clean/stage1/${lang}` ä»¥ä¸‹ã«æ¨è«–çµæœãŒå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚`AV-Romanizer`ã®å‡ºåŠ›çµæœã¨ã€`Cacaded Zero-AVSR`ã®å‡ºåŠ›çµæœã‚’ãã‚Œãã‚Œç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

`hypo.units` ã¯AV-RomanizerãŒå‡ºåŠ›ã—ãŸæ–‡å­—åˆ—ã§ã™ã€‚æ¬¡ã®æ¨è«–çµæœã¯ãƒ‰ã‚¤ãƒ„èªã‚’å…ƒã«ã—ã¦ã„ã¾ã™ãŒã€å‡ºåŠ›ãŒãƒ­ãƒ¼ãƒå­—ãªã®ã§ã‚¦ãƒ ãƒ©ã‚¦ãƒˆ(Ã¼ ãªã©)ãŒè¦‹å½“ãŸã‚Šã¾ã›ã‚“ã­ã€‚

```zero-avsr/evaluation/clean/stage1/deu/hypo.units
e i n e | g a n z | k l a s s i s c h e | a r t | a c h t s a m k e i t | z u | u e b e n | d a z u | m o e c h t e | i c h | s i e | g e r n e | j e t z t | e i n l a d e n | i n d e m | s i e | d i e | a u g e n | s c h l i e s s e n | s i c h | s o | b e q u e n e n | w i e | e s | g e r a d e | g e h t | h i n s a e t z e n | u n d | d i e | a u f m e r k s a m k e i t | n a c h | i n n e n | l e n k e n | z u | i h r e m | a t e m | (None-545)
d a s s | d a s | g a n z e | n a t u e r l i c h | a u c h | m a n c h m a l | i n | f e h e n s c h l a g | i s t | o d e r | a u c h | n a c h | w i e | v o r | n a c h | h i n t e n | g e h t | i s t | m i r | j e t z t | v o r | e i l e n | d i g e n | m o c h e n | g e g a n g k e n | d a | h a t t e | i f u r | m i c h | a u s g e s e h e n | e i n e n | s u p e r j o b | a n g e b o t | f u e r | e i n e r | d e r | g r o s t e n | a u t o m o b i e l h e r s t e l l e r | d i e | k o m p l e t t e | d i g i t a l i s i e r u n g | u n d | d i e | a u t o n o m e n | a u t o s | z u | l e i t e n | a l s o | w i r k l i c h | e i n | r i e s e n j o b | a b e r | i c h | h a b e | h i c r | n i c h t | b e k o m m e n | d a | w a r | n o c h | (None-292)
...
```

`avsr.json` ã¯GPT-4oã«ã‚ˆã£ã¦è£œæ­£ã•ã‚ŒãŸæ¨è«–çµæœã¨Ground Truthã®ãƒšã‚¢ã§ã™ã€‚

```zero-avsr/evaluation/clean/stage1/deu/avsr.json
[
    {
        "Ground truth": "und genau diese frage mussten wir kollegen eines groÃŸen europÃ¤ischen flugzeugherstellers beantworten\n",
        "prediction": "Und genau diese Frage mussten wir Kollegen eines groÃŸen europÃ¤ischen Flugzeugherstellers beantworten."
    },
    {
        "Ground truth": "das ist eine stadt in nordspanien eine alte arbeiterstadt sehr dreckige bergarbeiterstadt\n",
        "prediction": "Das in Nordspanien, dass ein alter Arbeiter statt sehr, sehr dreckige Bergarbeiter statt."
    },
    ...
]
```

### (Directly Integrated) Zero-AVSR ã‚’è©•ä¾¡ã™ã‚‹

```log
bash scripts/stage2/eval.sh

......

[2025-10-08 19:31:24,737][__main__][INFO] -
INST:Given romanized transcriptions extracted from audio-visual materials, back-transliterate them into the original script of German, Standard. Input:
REF:gebt es zu
HYP:gibt es zu

[2025-10-08 19:31:24,737][__main__][INFO] -
INST:Given romanized transcriptions extracted from audio-visual materials, back-transliterate them into the original script of German, Standard. Input:
REF:warum das denn
HYP:warum tat er das

......

[2025-10-08 19:31:24,748][__main__][INFO] -
German WER: 27.95071335927367%
German CER: 16.331652991921707%
```

## è‡ªæ’®ã‚Šã§è©¦ã—ã¦ã¿ã‚‹


